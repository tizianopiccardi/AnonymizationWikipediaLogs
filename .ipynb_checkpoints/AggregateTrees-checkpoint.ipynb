{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "import wmfdata\n",
    "spark = wmfdata.spark.get_session(\"yarn-large\")\n",
    "sc=spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import timedelta, date\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "DESTINATION_FOLDER = \"how_we_read_wikipedia_march/en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[access_method: string, country_code: string, session: array<struct<actual_destination:string,http_status:string,local_time:timestamp,page_id:bigint,page_title:string,prev_load:bigint,referer:string>>, timezone: string, user_identifier: string, previews: array<struct<http_status:string,local_time:timestamp,page_title:string,preview_title:string>>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_sessions = spark.read.parquet(\"{}/aggregated_sessions_final.parquet\".format(DESTINATION_FOLDER))\n",
    "aggregated_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from urllib.parse import unquote\n",
    "\n",
    "domains_wl = ['en.m.wikipedia.org', 'en.wikipedia.org']\n",
    "main_page = \"Main_Page\"\n",
    "\n",
    "class Tree:\n",
    "    \n",
    "    MAX_DEPTH = 300\n",
    "    \n",
    "    def __init__(self, referer, root, user_identifier, access_method, country_code):\n",
    "        self.referer = referer\n",
    "        self.user_identifier = user_identifier\n",
    "        self.access_method = access_method\n",
    "        self.tree = [root]\n",
    "        self.country_code = country_code\n",
    "    def get_as_dict(self):\n",
    "        return {\"user_identifier\": self.user_identifier, \n",
    "                \"access_method\": self.access_method,\n",
    "                \"country_code\": self.country_code,\n",
    "                \"referer\": self.referer,\n",
    "                \"tree_size\": self.size(),\n",
    "                \"tree\": self.visit_tree(self.tree[0], 0)}\n",
    "    def size(self):\n",
    "        queued = [self.tree[0]]\n",
    "        count = 0\n",
    "        while len(queued)>0:\n",
    "            node = queued.pop(0)\n",
    "            count+=1\n",
    "            for c in node.clicks:\n",
    "                queued.append(c)\n",
    "        return count\n",
    "        \n",
    "    def visit_tree(self, node, depth):\n",
    "        result = {\"page\": node.page_load}\n",
    "        clicks = []\n",
    "        if depth < self.MAX_DEPTH:\n",
    "            clicks = [self.visit_tree(c, depth+1) for c in node.clicks]\n",
    "        if len(clicks)>0:\n",
    "            result[\"clicks\"] = clicks\n",
    "        return result\n",
    "    def __repr__(self):\n",
    "        return \"{} --> {}\".format(self.referer, self.tree[0].page_load.get(\"page_title\"))\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, pl):\n",
    "        self.page_load = pl\n",
    "        self.clicks = []\n",
    "        self.clicks_titles = set()\n",
    "    def add_click(self, pl):\n",
    "        self.clicks.append(pl)\n",
    "        self.clicks_titles.add(pl.page_load.get(\"page_title\"))\n",
    "    def has_click(self, title):\n",
    "        return title in self.clicks_titles\n",
    "\n",
    "\n",
    "def get_trees(row):\n",
    "    trees = []\n",
    "    # Keep a pointer to the last time a page was open (title)\n",
    "    pointers_to_last = {}\n",
    "    \n",
    "    for pl_idx in range(0,  len(row.session)):\n",
    "        pl = row.session[pl_idx]\n",
    "        \n",
    "        #########################################\n",
    "        # Get page title from the resolved redirect\n",
    "        #########################################\n",
    "        page_title = unquote(pl.actual_destination)\n",
    "        \n",
    "        # Get referer\n",
    "        parsed_referer_url = urlparse(unquote(pl.referer))\n",
    "        referer_url = parsed_referer_url.netloc\n",
    "        referer_path = parsed_referer_url.path\n",
    "        \n",
    "        # Get status code\n",
    "        http_status = pl.http_status\n",
    "        \n",
    "        # Get page id\n",
    "        page_id = pl.page_id\n",
    "        \n",
    "        # Get timestap\n",
    "        local_time = pl.local_time.timestamp()\n",
    "        \n",
    "        #########################################\n",
    "        # Type: Reload\n",
    "        # Description: Handle a very obvious case of reload (2 consecutive)\n",
    "        # Action: Skip\n",
    "        #########################################\n",
    "        if pl_idx > 0:\n",
    "            prev = row.session[pl_idx-1]\n",
    "            if pl.page_title == prev.page_title and pl.referer == prev.referer:\n",
    "                continue\n",
    "            \n",
    "        \n",
    "        #########################################\n",
    "        # Type: Main Page\n",
    "        # Description: Main page should not be part of the navigation\n",
    "        # Action: Update referer as external to Wikipedia to spawn a new tree \n",
    "        #########################################\n",
    "        if referer_url in domains_wl and referer_path == \"/wiki/{}\".format(main_page):\n",
    "            referer_url = \"\"\n",
    "            referer_path = main_page\n",
    "        if page_title == main_page:\n",
    "            continue\n",
    "        \n",
    "        pageload_info = {#referer = referer_url+referer_path,\n",
    "            \"page_title\": page_title,\n",
    "            \"page_id\": page_id,\n",
    "            \"local_time\": local_time,\n",
    "            \"http_status\": http_status\n",
    "        }\n",
    "        \n",
    "        # Create the node of the tree\n",
    "        page_load = Node(pageload_info)\n",
    "        \n",
    "        \n",
    "        # Check if we have to spawn a new tree\n",
    "        if referer_url not in domains_wl or not referer_path.startswith(\"/wiki/\"):\n",
    "            # Create a new tree\n",
    "            session_tree = Tree(pl.referer, page_load, row.user_identifier, row.access_method, row.country_code)\n",
    "            trees.append(session_tree)\n",
    "        # ... else if the referer is a Wikipedia page\n",
    "        elif referer_url in domains_wl and referer_path.startswith(\"/wiki/\"):\n",
    "            # Search for the last time it was loaded\n",
    "            referer_page_title = parsed_referer_url.path[6:]\n",
    "            last_load_node = pointers_to_last.get(referer_page_title)\n",
    "            # Add the child\n",
    "            if last_load_node and not last_load_node.has_click(page_title):\n",
    "                last_load_node.add_click(page_load)\n",
    "            else:\n",
    "                # Skip the next step: adding to index\n",
    "                # Remember, this would be a reload and we want to keep\n",
    "                # as reference the first load.\n",
    "                continue\n",
    "        \n",
    "        # Add the node to the index\n",
    "        # Info: useful to quickly find the last load of the page\n",
    "        pointers_to_last[page_title] = page_load\n",
    "\n",
    "    return trees\n",
    "\n",
    "# def get_trees_as_dict(row):\n",
    "#     return [Row(user_identifier=t.user_identifier, \n",
    "#                 referer=t.referer, access_method=t.access_method, tree_size=t.size(),\n",
    "#                page_id=t.tree[0].page_load['page_id']) for t in get_trees(row)]\n",
    "\n",
    "def get_trees_as_dict(row):\n",
    "    return [t.get_as_dict() for t in get_trees(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = aggregated_sessions.rdd.flatMap(get_trees_as_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "trees.map(lambda r: json.dumps(r))\\\n",
    "        .saveAsTextFile(path=\"{}/trees_sessions_final.json.gz\".format(DESTINATION_FOLDER), \n",
    "                        compressionCodecClass=\"org.apache.hadoop.io.compress.GzipCodec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_identifier': 'd0461388d387b1e715dcf6cad16fd2253ef3ced639a4d9e7702bb355b55d5614',\n",
       "  'access_method': 'mobile web',\n",
       "  'country_code': 'US',\n",
       "  'referer': 'https://www.google.com/',\n",
       "  'tree_size': 1,\n",
       "  'tree': {'page': {'page_title': 'Pooh_Shiesty',\n",
       "    'page_id': 66130325,\n",
       "    'local_time': 1615663398.0,\n",
       "    'http_status': '200'}}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.take(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
